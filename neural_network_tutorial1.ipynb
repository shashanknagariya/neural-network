{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyg38VRVmLUMgGGws9ME1e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shashanknagariya/neural-network/blob/main/neural_network_tutorial1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nnfs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6SKJbqQe1sE",
        "outputId": "30f1be97-1ce6-4a8f-d4de-c8b5beb77c27"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nnfs\n",
            "  Downloading nnfs-0.5.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from nnfs) (2.0.2)\n",
            "Downloading nnfs-0.5.1-py3-none-any.whl (9.1 kB)\n",
            "Installing collected packages: nnfs\n",
            "Successfully installed nnfs-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gxijzuDBeMaB"
      },
      "outputs": [],
      "source": [
        "from nnfs.datasets import spiral_data\n",
        "import numpy as np\n",
        "import nnfs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = spiral_data(100,3)"
      ],
      "metadata": {
        "id": "SCqog0ScevpL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DENSE LAYER CLASS**"
      ],
      "metadata": {
        "id": "dH33CMOafiti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nnfs.init()\n",
        "\n",
        "class LayerDense:\n",
        "  \"\"\"\n",
        "  A layer of neurons. This is called Layer Dense because\n",
        "  every neuron in the previous layer connects to every\n",
        "  neuron in the next layer.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,n_inputs,n_neurons):\n",
        "    \"\"\"\n",
        "    class initialised with number of inputs and number of neurons\n",
        "    weights are randomly initialised between -1 and 1\n",
        "    biases are initialised to 0\n",
        "    weights are nothing but the connections between the neurons\n",
        "    biases are nothing but the biases of the neurons\n",
        "\n",
        "    biases of neuron means how much the neuron is activated\n",
        "    \"\"\"\n",
        "    self.weights = 0.10 * np.random.randn(n_inputs,n_neurons)\n",
        "    self.biases = np.zeros((1,n_neurons))\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    \"\"\"\n",
        "    forward pass of the layer.\n",
        "    inputs are multiplied by the weights and added to the biases\n",
        "    \"\"\"\n",
        "    self.output = np.dot(inputs,self.weights) + self.biases"
      ],
      "metadata": {
        "id": "pJ1yLHaVfL9P"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense1 = LayerDense(2,3)\n",
        "dense1.forward(x)\n",
        "print(dense1.output[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS3-k3NZg1Wz",
        "outputId": "e3a15e38-7178-4b97-c1b0-dce7f133ef3c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.          0.          0.        ]\n",
            " [ 0.00231199  0.00189689 -0.0009594 ]\n",
            " [ 0.00233242  0.00295563 -0.00267016]\n",
            " [ 0.00766013  0.00578583 -0.00236353]\n",
            " [ 0.01053444  0.00771121 -0.00284911]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ACTIVATION FUNCTION: RELU**"
      ],
      "metadata": {
        "id": "sBaopMiNhzxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ActivationReLU:\n",
        "  def forward(self,inputs):\n",
        "    \"\"\"\n",
        "    forward pass of the activation function.\n",
        "    relu is applied to the inputs\n",
        "    \"\"\"\n",
        "    self.output = np.maximum(0,inputs)"
      ],
      "metadata": {
        "id": "5-4sbhIOhjwd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "activation_1 = ActivationReLU()\n",
        "activation_1.forward(dense1.output)\n",
        "print(activation_1.output[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPa8B-baiERq",
        "outputId": "9b79a6f8-50ff-4b8b-ec56-30682ff6c3c4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.        ]\n",
            " [0.00231199 0.00189689 0.        ]\n",
            " [0.00233242 0.00295563 0.        ]\n",
            " [0.00766013 0.00578583 0.        ]\n",
            " [0.01053444 0.00771121 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ACTIVATION FUNCTION: SOFTMAX**"
      ],
      "metadata": {
        "id": "zwIHLlb5iWR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ActivationSoftMax:\n",
        "  def forward(self,inputs):\n",
        "    \"\"\"\n",
        "    forward pass of the activation function.\n",
        "    softmax is applied to the inputs\n",
        "    where we subtract the maximum value from the inputs to avoid\n",
        "    overflow\n",
        "    and then take exponential of the result\n",
        "    and then divide by the sum of the exponential of the result\n",
        "    \"\"\"\n",
        "    exp_values = np.exp(inputs - np.max(inputs,axis=1,keepdims=True))\n",
        "    probabilities = exp_values / np.sum(exp_values,axis=1,keepdims=True)\n",
        "    self.output = probabilities\n"
      ],
      "metadata": {
        "id": "ZbaYwNEriVuQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#make a forward pass through second dense layer\n",
        "#it takes outputs of activation function of first layer as inputs\n",
        "dense2 = LayerDense(3,3)\n",
        "dense2.forward(activation_1.output)\n",
        "print(dense2.output[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULG0wsyPiQxJ",
        "outputId": "33865f71-4b01-44dd-db09-452d3aa85f50"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [ 2.9754589e-04 -7.6702145e-06  2.5199552e-04]\n",
            " [ 3.4295820e-04  7.2711578e-06  4.0575486e-04]\n",
            " [ 9.6534507e-04 -3.2600368e-05  7.6235103e-04]\n",
            " [ 1.3174859e-03 -4.8371196e-05  1.0126863e-03]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#make a forward pass through activation function\n",
        "#it takes the output of the second dense layer here\n",
        "activation_2 = ActivationSoftMax()\n",
        "activation_2.forward(dense2.output)\n",
        "print(activation_2.output[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Flgwpajjj84t",
        "outputId": "1662eae0-4077-47b4-e240-22f26f168d0a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.33333334 0.33333334 0.33333334]\n",
            " [0.3333723  0.33327058 0.3333571 ]\n",
            " [0.33336365 0.33325174 0.33338457]\n",
            " [0.33346677 0.33313417 0.33339906]\n",
            " [0.33351895 0.33306375 0.3334173 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CALCULATING NETWORK ERROR WITH LOSS**"
      ],
      "metadata": {
        "id": "UJds2mFPkaUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# There are two ways to calculate network error with loss\n",
        "# 1. CROSS ENTROPY LOSS BUILDING BLOCKS\n",
        "# 2. IF DATA IS HOT ENCODED"
      ],
      "metadata": {
        "id": "JOqOSw1IkVgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CROSS ENTROPY LOSS BUILDING BLOCKS**"
      ],
      "metadata": {
        "id": "dVwnLsNylAfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "softmax_outpus = np.array([[]])"
      ],
      "metadata": {
        "id": "p_ng9IHmlHAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2507a89"
      },
      "source": [
        "# Generate a random softmax output for demonstration\n",
        "# This is a placeholder and would normally come from the network's forward pass\n",
        "random_softmax_output = np.array([[0.7, 0.2, 0.1],\n",
        "                                 [0.1, 0.8, 0.1],\n",
        "                                 [0.3, 0.3, 0.4]])\n",
        "\n",
        "# Define the class targets (e.g., the true classes for each sample)\n",
        "# These would typically be the 'y' values from your dataset\n",
        "class_targets = np.array([0, 1, 2])\n",
        "\n",
        "print(\"Random Softmax Output:\")\n",
        "print(random_softmax_output)\n",
        "print(\"\\nClass Targets:\")\n",
        "print(class_targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5ee2f99"
      },
      "source": [
        "Now, let's see how to extract the relevant probabilities from the softmax output based on the `class_targets`. We want to get the probability that the model assigned to the *correct* class for each sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c97c316d"
      },
      "source": [
        "# Extract the probabilities corresponding to the true class targets\n",
        "# We use np.arange(len(random_softmax_output)) to get indices for each row\n",
        "# and class_targets to get the column index for the correct class in each row\n",
        "relevant_probabilities = random_softmax_output[np.arange(len(random_softmax_output)), class_targets]\n",
        "\n",
        "print(\"Relevant Probabilities (probabilities of the true classes):\")\n",
        "print(relevant_probabilities)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8371ac7"
      },
      "source": [
        "These `relevant_probabilities` are the values we will use to calculate the loss, specifically the cross-entropy loss. A higher probability for the true class indicates a lower loss and better model performance."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LOSS:\n",
        "  def calculate(self, output, y):\n",
        "    \"\"\"\n",
        "    calculate the data and regularization losses\n",
        "    given model output and ground truth values\n",
        "    here output is the softmax output and y is the class targets\n",
        "    \"\"\"\n",
        "    sample_losses = self.forward(output, y)\n",
        "    data_loss = np.mean(sample_losses)\n",
        "    return data_loss"
      ],
      "metadata": {
        "id": "_AiUu-VAnxPT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LossCategoricalCrossEntropy(LOSS):\n",
        "  def forward(self,y_pred,y_true):\n",
        "    \"\"\"\n",
        "    forward pass of the categorical cross entropy loss\n",
        "    \"\"\"\n",
        "    #number of samples in a batch\n",
        "    sample_data = len(y_pred)\n",
        "    #clip data to prevent dvision by 0\n",
        "    # clip both side to not drag mean towards any value\n",
        "    # what if y_pred becomes 0 then log will be inf and\n",
        "    #if y_pred becomes 1 then log will be -\n",
        "    y_pred_clipped = np.clip(y_pred,1e-7,1-1e-7)\n",
        "    #probabilities for target values\n",
        "    # only if categorical labels\n",
        "    if len(y_true.shape) == 1:\n",
        "      correct_confidences = y_pred_clipped[range(sample_data),y_true]\n",
        "    elif len(y_true.shape) == 2:\n",
        "      correct_confidences = np.sum(y_pred_clipped*y_true,axis=1)\n",
        "    #losses\n",
        "    negative_log_likelihoods = -np.log(correct_confidences)\n",
        "    return negative_log_likelihoods\n"
      ],
      "metadata": {
        "id": "Lm0RwBchoPXN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = LossCategoricalCrossEntropy()\n",
        "loss = loss_function.calculate(activation_2.output,y)\n",
        "print(\"Loss:\",loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr5YV9hNpP9W",
        "outputId": "e112534c-7ea7-4bf9-af51-18b613f4c0f5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 1.0986664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define an Accuracy class\n",
        "class Accuracy:\n",
        "  def calculate(self, predictions, y):\n",
        "    \"\"\"\n",
        "    Calculates the accuracy given predictions and true labels.\n",
        "    \"\"\"\n",
        "    # Compare predictions to true labels and calculate accuracy\n",
        "    accuracy = np.mean(predictions == y)\n",
        "    return accuracy\n",
        "\n",
        "# Calculate the predictions by taking the index of the highest probability\n",
        "# if highest probability index is same as class target that means accuracy is\n",
        "#perfect\n",
        "predictions = np.argmax(activation_2.output, axis=1)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy_metric = Accuracy()\n",
        "accuracy = accuracy_metric.calculate(predictions, y)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTf3PurRp8A0",
        "outputId": "55db8bb5-cef5-43d8-91bd-167da75ff03f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_3L_ZzuiqsRP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}